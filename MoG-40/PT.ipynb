{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from samplers.ParallelTempering import parallel_tempering_step\n",
    "import numpy as np\n",
    "from utils import GMM, quadratic_function, MC_estimate_true_expectation, relative_mae, plot_contours\n",
    "from mmd import MMD_loss\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda')\n",
    "torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 2\n",
    "n_mixes = 40\n",
    "loc_scaling = 40.0  # scale of the problem (changes how far apart the modes of each Guassian component will be)\n",
    "log_var_scaling = 1.0 # variance of each Gaussian\n",
    "\n",
    "torch.manual_seed(0)  # seed of 0 for GMM problem\n",
    "target = GMM(dim=dim, n_mixes=n_mixes,\n",
    "              loc_scaling=loc_scaling, log_var_scaling=log_var_scaling,\n",
    "              device=device)\n",
    "\n",
    "energy = lambda x: -target.log_prob(x)\n",
    "\n",
    "plotting_bounds = (-loc_scaling * 1.4, loc_scaling * 1.4)\n",
    "\n",
    "n_samples = int(1e4)\n",
    "true_samples = target.sample([n_samples])\n",
    "plot_contours(target.log_prob, samples=true_samples.cpu().numpy(), bounds=plotting_bounds, n_contour_levels=50, grid_width_n_points=200, device=device, plt_show=False)\n",
    "\n",
    "true_expectation = MC_estimate_true_expectation(true_samples.cpu(), quadratic_function)\n",
    "print(\"True Expectation:\", true_expectation.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000\n",
    "num_chains = 10\n",
    "step_size = 1e-1\n",
    "num_leapfrog_steps_per_hmc_step = 10\n",
    "num_hmc_steps = 20\n",
    "\n",
    "# (inverse) temperature schedule\n",
    "num_temperatures = 5\n",
    "inv_temperatures = [0.0 for _ in range(num_temperatures)]\n",
    "b_min = 0.001\n",
    "\n",
    "for r in range(num_temperatures):\n",
    "    t = r / (num_temperatures - 1)\n",
    "    inv_temperatures[r] = b_min ** t\n",
    "print(\"Temperatures:\", [round(1.0/inv_t, 2) for inv_t in inv_temperatures])\n",
    "\n",
    "x = [torch.zeros([num_chains, dim], device=device) for _ in range(num_temperatures)]\n",
    "\n",
    "energy = lambda x: -target.log_prob(x)\n",
    "\n",
    "samples = []\n",
    "for _ in tqdm(range(num_samples//num_chains)):\n",
    "    chains = parallel_tempering_step(x, num_temperatures, energy, step_size, num_leapfrog_steps_per_hmc_step, num_hmc_steps, inv_temperatures, device)\n",
    "    samples.append(chains[0].detach())\n",
    "samples = torch.cat(samples, dim=0)\n",
    "plot_contours(target.log_prob, samples=samples.cpu().numpy(), bounds=plotting_bounds, n_contour_levels=50, grid_width_n_points=200, device=device, plt_show=True)\n",
    "\n",
    "expectation = MC_estimate_true_expectation(samples.cpu(), quadratic_function)\n",
    "print(\"Expectation:\", expectation.cpu().numpy())\n",
    "\n",
    "print(\"Relative MAE:\", relative_mae(true_expectation, expectation).item())\n",
    "\n",
    "mmd_loss=MMD_loss(kernel_num=5)\n",
    "mmd=mmd_loss.forward(source=samples.cpu(), target=true_samples.cpu())\n",
    "print(\"MMD:\", mmd.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdgs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
